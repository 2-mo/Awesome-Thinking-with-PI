


Hyperbolic Safety-Aware Vision-Language Models (CVPR 2025) [![GitHub stars](https://img.shields.io/github/stars/aimagelab/HySAC?style=social&label=GitHub&logo=github)](https://github.com/aimagelab/HySAC) [![Project](https://img.shields.io/badge/Project-blue?logo=safari)](https://aimagelab.github.io/HySAC/)

![HySAC method](assets/hysac-method.png)

[![HyperCLIP](https://img.shields.io/badge/To--Sort-HyperCLIP-lightgrey?logo=github)](https://github.com/SJTU-DeepVisionLab/HyperCLIP)
[![TreeVGR](https://img.shields.io/badge/To--Sort-TreeVGR-lightgrey?logo=github)](https://github.com/Haochen-Wang409/TreeVGR)



EntitySeg Toolbox（开放世界分割） [代码](https://github.com/qqlu/Entity)


可能的数据集
**Pixels, Patterns, but No Poetry: To See The World like Humans**
Pixels, Patterns, but No Poetry: To See The World like Humans
**主要内容**: 中科院等提出Turing Eye Test基准，发现现有多模态大模型在感知任务上与人类差距明显。
**链接**: https://TuringEyeTest.github.io