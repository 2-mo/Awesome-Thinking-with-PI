<p align="center">
  <img src="https://raw.githubusercontent.com/ligeng0197/Awesome-Thinking-With-Images/main/assets/logo.png" alt="Awesome Thinking with PI" width="180">
</p>

<h1 align="center">Awesome Thinking with PI (Perception & Interaction)</h1>

<p align="center">
  <b>A curated list of resources on visual reasoning, video understanding, embodied AI, robot action, and perception-driven interaction.</b>
</p>

<!-- È°∂ÈÉ®ÂæΩÁ´†Âå∫ÔºàBadgesÔºâ -->
<p align="center">
  <a href="https://github.com/ligeng0197/Awesome-Thinking-With-Images/stargazers"><img src="https://img.shields.io/github/stars/ligeng0197/Awesome-Thinking-With-Images?style=social"></a>
  <a href="https://github.com/ligeng0197/Awesome-Thinking-With-Images/blob/main/LICENSE"><img src="https://img.shields.io/github/license/ligeng0197/Awesome-Thinking-With-Images?color=blueviolet"></a>
  <a href="https://github.com/ligeng0197/Awesome-Thinking-With-Images/graphs/contributors"><img src="https://img.shields.io/github/contributors/ligeng0197/Awesome-Thinking-With-Images?color=ffaa00"></a>
</p>

---

## üìö Contents

- üß† [Reasoning as <think>](#reasoning-as-think)
- üñºÔ∏è [Think with Images](#think-with-images)
- ü§ñ [Embodied Intelligence (ÂÖ∑Ë∫´Êô∫ËÉΩ)](#ÂÖ∑Ë∫´Êô∫ËÉΩ)
- ü§ù [Contributing](#contributing)

---

<p align="center">
  <img src="https://raw.githubusercontent.com/ligeng0197/Awesome-Thinking-With-Images/main/assets/divider.png" alt="divider" width="60%">
</p>

---

## üß† Reasoning as &lt;think&gt;

---

### Open R1 Video

[![Project](https://img.shields.io/badge/Project-Homepage-blue?logo=googlechrome)](https://github.com/Wang-Xiaodong1899/Open-R1-Video)
[![Code](https://img.shields.io/badge/Code-GitHub-black?logo=github)](https://github.com/Wang-Xiaodong1899/Open-R1-Video)
![GitHub Repo stars](https://img.shields.io/github/stars/Wang-Xiaodong1899/Open-R1-Video?style=social)

![Open R1 Video](assets/image-20250620102641966.png)

---

### Video-R1: Reinforcing Video Reasoning in MLLMs

[![arXiv](https://img.shields.io/badge/arXiv-2503.21776-b31b1b?logo=arxiv)](https://arxiv.org/pdf/2503.21776)
[![Zhihu](https://img.shields.io/badge/Zhihu-Ëß£ËØª-informational?logo=zhihu)](https://zhuanlan.zhihu.com/p/1889342435928282728)
[![Project](https://img.shields.io/badge/Project-Homepage-blue?logo=googlechrome)](https://github.com/tulerfeng/Video-R1)
[![Code](https://img.shields.io/badge/Code-GitHub-black?logo=github)](https://github.com/tulerfeng/Video-R1)
![GitHub Repo stars](https://img.shields.io/github/stars/tulerfeng/Video-R1?style=social)

![Video-R1](assets/image-20250620102641966.png)

---

### VideoChat-R1: Enhancing Spatio-Temporal Perception via Reinforcement Fine-Tuning

[![arXiv](https://img.shields.io/badge/arXiv-2504.06958-b31b1b?logo=arxiv)](https://arxiv.org/pdf/2504.06958)
[![Project](https://img.shields.io/badge/Project-Homepage-blue?logo=googlechrome)](https://github.com/OpenGVLab/VideoChat-R1)
[![Code](https://img.shields.io/badge/Code-GitHub-black?logo=github)](https://github.com/OpenGVLab/VideoChat-R1)
![GitHub Repo stars](https://img.shields.io/github/stars/OpenGVLab/VideoChat-R1?style=social)

![VideoChat-R1](assets/image-20250620144735572.png)

---

### TinyLLaVA-Video-R1: Towards Smaller LMMs for Video Reasoning

[![arXiv](https://img.shields.io/badge/arXiv-2504.09641-b31b1b?logo=arxiv)](https://arxiv.org/pdf/2504.09641)
[![Project](https://img.shields.io/badge/Project-Homepage-blue?logo=googlechrome)](https://github.com/ZhangXJ199/TinyLLaVA-Video-R1)
[![Code](https://img.shields.io/badge/Code-GitHub-black?logo=github)](https://github.com/ZhangXJ199/TinyLLaVA-Video-R1)
![GitHub Repo stars](https://img.shields.io/github/stars/ZhangXJ199/TinyLLaVA-Video-R1?style=social)

![TinyLLaVA-Video-R1](assets/image-20250620103826723.png)

---

## üñºÔ∏è Think with Images

<!-- ÊåâÂêåÊ†∑Âç°ÁâáÊ†ºÂºèË°•ÂÖÖÂÜÖÂÆπ -->

---

## ü§ñ ÂÖ∑Ë∫´Êô∫ËÉΩ (Embodied Intelligence)

---

### Embodied-Reasoner: Synergizing Visual Search, Reasoning, and Action for Embodied Interactive Tasks

[![arXiv](https://img.shields.io/badge/arXiv-2503.21696-b31b1b?logo=arxiv)](https://arxiv.org/pdf/2503.21696v1)
[![Project](https://img.shields.io/badge/Project-Homepage-blue?logo=googlechrome)](https://embodied-reasoner.github.io/)
[![Code](https://img.shields.io/badge/Code-GitHub-black?logo=github)](https://github.com/zwq2018/embodied_reasoner)
![GitHub Repo stars](https://img.shields.io/github/stars/zwq2018/embodied_reasoner?style=social)

![Embodied-Reasoner](assets/image-20250620115046795.png)

---

### Reason-RFT: Reinforcement Fine-Tuning for Visual Reasoning

[![arXiv](https://img.shields.io/badge/arXiv-2503.20752-b31b1b?logo=arxiv)](https://arxiv.org/abs/2503.20752)
[![Project](https://img.shields.io/badge/Project-Homepage-blue?logo=googlechrome)](https://tanhuajie.github.io/ReasonRFT/)
[![Code](https://img.shields.io/badge/Code-GitHub-black?logo=github)](https://github.com/tanhuajie/Reason-RFT)
![GitHub Repo stars](https://img.shields.io/github/stars/tanhuajie/Reason-RFT?style=social)

![Reason-RFT](assets/teaser.png)

---

### Think Small, Act Big: Primitive Prompt Learning for Lifelong Robot Manipulation

[![CVPR 2025](https://img.shields.io/badge/CVPR2025-Paper-blueviolet?logo=opencv)](https://openaccess.thecvf.com/content/CVPR2025/papers/Yao_Think_Small_Act_Big_Primitive_Prompt_Learning_for_Lifelong_Robot_CVPR_2025_paper.pdf)

![Think Small, Act Big](assets/image-20250630111854316.png)

---

### OpenFly: A Versatile Toolchain and Large-scale Benchmark for Aerial Vision-Language Navigation

[![Project](https://img.shields.io/badge/Project-Homepage-blue?logo=googlechrome)](https://shailab-ipec.github.io/openfly/)

![OpenFly](assets/toolchain.png)

---

### SAM-R1: Leveraging SAM for Reward Feedback in Multimodal Segmentation via RL

[![arXiv](https://img.shields.io/badge/arXiv-2505.22596-b31b1b?logo=arxiv)](https://arxiv.org/pdf/2505.22596)

![SAM-R1](assets/image-20250630112453520.png)

---

### Visual-RFT: Visual Reinforcement Fine-Tuning

[![arXiv](https://img.shields.io/badge/arXiv-2503.01785-b31b1b?logo=arxiv)](https://arxiv.org/pdf/2503.01785)
[![Code](https://img.shields.io/badge/Code-GitHub-black?logo=github)](https://github.com/Liuziyu77/Visual-RFT)
![GitHub Repo stars](https://img.shields.io/github/stars/Liuziyu77/Visual-RFT?style=social)

![Visual-RFT](assets/image-20250630104729762.png)

---

### Visual Planning: Let's Think Only with Images

[![arXiv](https://img.shields.io/badge/arXiv-2505.11409-b31b1b?logo=arxiv)](https://arxiv.org/pdf/2505.11409)
[![Code](https://img.shields.io/badge/Code-GitHub-black?logo=github)](https://github.com/yix8/VisualPlanning)
![GitHub Repo stars](https://img.shields.io/github/stars/yix8/VisualPlanning?style=social)

![Visual Planning](assets/image-20250630105040047.png)

---

### AgentThink: A Unified Framework for Tool-Augmented Chain-of-Thought Reasoning in Vision-Language Models for Autonomous Driving

[![arXiv](https://img.shields.io/badge/arXiv-2505.15298-b31b1b?logo=arxiv)](https://arxiv.org/pdf/2505.15298)

![AgentThink](assets/image-20250725211337583.png)

---

## ü§ù Contributing

Contributions are welcome! Please submit a pull request to add papers, code, or resources.

---

<!-- Âø´Êç∑ËÆøÈóÆÊåâÈíÆÂå∫ -->
<p align="center">
  <a href="https://github.com/ligeng0197/Awesome-Thinking-With-Images"><img src="https://img.shields.io/badge/GitHub-Repo-black?logo=github"></a>
  <a href="https://github.com/ligeng0197/Awesome-Thinking-With-Images/issues"><img src="https://img.shields.io/badge/Issues-Track-orange"></a>
  <a href="https://github.com/ligeng0197/Awesome-Thinking-With-Images/pulls"><img src="https://img.shields.io/badge/Pull%20Requests-Welcome-brightgreen"></a>
  <a href="https://github.com/ligeng0197/Awesome-Thinking-With-Images/commits/main"><img src="https://img.shields.io/badge/Commits-Main-blue"></a>
  <a href="https://github.com/ligeng0197/Awesome-Thinking-With-Images/graphs/contributors"><img src="https://img.shields.io/badge/Contributors-Graph-ffaa00"></a>
</p>

---

**Inspired by awesome-lists and the community‚Äôs effort on visual and embodied AI.**
